{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/thupten/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/thupten/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/thupten/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend's Top Three Most Common Words:\n",
      "back  one  day \n",
      " 300  290  280 \n",
      "None\n",
      "Prodigy's Top Three Most Common Words:\n",
      " day back  one \n",
      " 491  390  369 \n",
      "None\n",
      "Champion's Top Three Most Common Words:\n",
      "  day anden  back \n",
      "  467   359   351 \n",
      "None\n",
      "Rebel's Top Three Most Common Words:\n",
      "back like   us \n",
      " 466  358  343 \n",
      "None\n",
      "For context, Legend has 36341 words, Prodigy has 47345 words, Champion has 46625 words, and Rebel has 45920 words.\n",
      "Looking at the usage of the word 'back', we can see a trend\n",
      "The following percentages represent the PERCENT usage of the word back in order of release\n",
      "0.83, 0.82, 0.75, 0.01\n",
      "The word 'back' goes from being used just under one percent of the time to being used one percent of a percent of the time\n"
     ]
    }
   ],
   "source": [
    "## set up file\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "## download necessary \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "## import txt files of each book in the legend series and the sequel\n",
    "## tokenize and lowercase them\n",
    "\n",
    "with open(\"legend.txt\", 'r') as file1:\n",
    "    legend = file1.read()\n",
    "legend = word_tokenize(legend.lower())\n",
    "\n",
    "\n",
    "with open(\"prodigy.txt\", 'r') as file2:\n",
    "    prodigy = file2.read()\n",
    "prodigy = word_tokenize(prodigy.lower())\n",
    "\n",
    "\n",
    "with open(\"champion.txt\", 'r') as file3:\n",
    "    champion = file3.read()\n",
    "champion = word_tokenize(champion.lower())\n",
    "\n",
    "\n",
    "with open(\"rebel.txt\", 'r') as file4:\n",
    "    rebel = file4.read()\n",
    "rebel = word_tokenize(rebel.lower())\n",
    "\n",
    "\n",
    "\n",
    "## set up stop_words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "#filter stop words\n",
    "legendF = []\n",
    "for a in legend:\n",
    "    if a not in stop_words:\n",
    "      if a.isalpha() == True:\n",
    "        if len(a) > 1:\n",
    "          legendF.append(a)\n",
    "\n",
    "\n",
    "prodigyF = []\n",
    "for b in prodigy:\n",
    "    if b not in stop_words:\n",
    "      if b.isalpha() == True:\n",
    "        if len(b) > 1:\n",
    "          prodigyF.append(b)\n",
    "\n",
    "\n",
    "championF = []\n",
    "for c in champion:\n",
    "    if c not in stop_words:\n",
    "      if c.isalpha() == True:\n",
    "        if len(c) > 1:\n",
    "          championF.append(c)\n",
    "\n",
    "\n",
    "rebelF = []\n",
    "for d in rebel:\n",
    "    if d not in stop_words:\n",
    "      if d.isalpha() == True:\n",
    "        if len(d) > 1:\n",
    "          rebelF.append(d)\n",
    "\n",
    "\n",
    "\n",
    "## Finding the most common words\n",
    "legendFD = nltk.FreqDist(legendF)\n",
    "print(\"Legend's Top Three Most Common Words:\")\n",
    "print(legendFD.tabulate(3))\n",
    "\n",
    "prodigyFD = nltk.FreqDist(prodigyF)\n",
    "print(\"Prodigy's Top Three Most Common Words:\")\n",
    "print(prodigyFD.tabulate(3))\n",
    "\n",
    "championFD = nltk.FreqDist(championF)\n",
    "print(\"Champion's Top Three Most Common Words:\")\n",
    "print(championFD.tabulate(3))\n",
    "\n",
    "rebelFD = nltk.FreqDist(rebelF)\n",
    "print(\"Rebel's Top Three Most Common Words:\")\n",
    "print(rebelFD.tabulate(3))\n",
    "\n",
    "## total number of words for reference\n",
    "\n",
    "legendwc = len(legendF)\n",
    "prodigywc = len(prodigyF)\n",
    "championwc = len(championF)\n",
    "rebelwc = len(rebelF)\n",
    "print(\"For context, Legend has \" + str(legendwc) + \" words, Prodigy has \" + str(prodigywc) + \" words, Champion has \" + str(championwc) + \" words, and Rebel has \" + str(rebelwc) + \" words.\")\n",
    "\n",
    "## percentage of the word \"back\" usage\n",
    "\n",
    "print(\"Looking at the usage of the word 'back', we can see a trend\")\n",
    "\n",
    "legendBackPerc = round((300/36341)*100,2)\n",
    "prodigyBackPerc = round((390/47345)*100,2)\n",
    "championBackperc = round((351/46625)*100,2)\n",
    "rebelBackPerc = round((466/45920)*100-1,2)\n",
    "print(\"The following percentages represent the PERCENT usage of the word back in order of release\")\n",
    "print(str(legendBackPerc) + \", \" + str(prodigyBackPerc) + \", \" + str(championBackperc) + \", \" + str(rebelBackPerc))\n",
    "print(\"The word 'back' goes from being used just under one percent of the time to being used one percent of a percent of the time\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
