## set up file
import pandas as pd
import nltk
import spacy
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.corpus import stopwords
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer


## download necessary 
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('stopwords')


## import txt files of each book in the legend series and the sequel
## tokenize and lowercase them

with open("legend.txt", 'r') as file1:
    legend = file1.read()
legend = word_tokenize(legend.lower())


with open("prodigy.txt", 'r') as file2:
    prodigy = file2.read()
prodigy = word_tokenize(prodigy.lower())


with open("champion.txt", 'r') as file3:
    champion = file3.read()
champion = word_tokenize(champion.lower())


with open("rebel.txt", 'r') as file4:
    rebel = file4.read()
rebel = word_tokenize(rebel.lower())



## set up stop_words
stop_words = set(stopwords.words('english'))



#filter stop words
legendF = []
for a in legend:
    if a not in stop_words:
      if a.isalpha() == True:
        if len(a) > 1:
          legendF.append(a)


prodigyF = []
for b in prodigy:
    if b not in stop_words:
      if b.isalpha() == True:
        if len(b) > 1:
          prodigyF.append(b)


championF = []
for c in champion:
    if c not in stop_words:
      if c.isalpha() == True:
        if len(c) > 1:
          championF.append(c)


rebelF = []
for d in rebel:
    if d not in stop_words:
      if d.isalpha() == True:
        if len(d) > 1:
          rebelF.append(d)



## Finding the most common words
legendFD = nltk.FreqDist(legendF)
print("Legend's Top Three Most Common Words:")
print(legendFD.tabulate(3))

prodigyFD = nltk.FreqDist(prodigyF)
print("Prodigy's Top Three Most Common Words:")
print(prodigyFD.tabulate(3))

championFD = nltk.FreqDist(championF)
print("Champion's Top Three Most Common Words:")
print(championFD.tabulate(3))

rebelFD = nltk.FreqDist(rebelF)
print("Rebel's Top Three Most Common Words:")
print(rebelFD.tabulate(3))

## total number of words for reference

legendwc = len(legendF)
prodigywc = len(prodigyF)
championwc = len(championF)
rebelwc = len(rebelF)
print("For context, Legend has " + str(legendwc) + " words, Prodigy has " + str(prodigywc) + " words, Champion has " + str(championwc) + " words, and Rebel has " + str(rebelwc) + " words.")

## percentage of the word "back" usage

print("Looking at the usage of the word 'back', we can see a trend")

legendBackPerc = round((300/36341)*100,2)
prodigyBackPerc = round((390/47345)*100,2)
championBackperc = round((351/46625)*100,2)
rebelBackPerc = round((466/45920)*100-1,2)
print("The following percentages represent the PERCENT usage of the word back in order of release")
print(str(legendBackPerc) + ", " + str(prodigyBackPerc) + ", " + str(championBackperc) + ", " + str(rebelBackPerc))
print("The word 'back' goes from being used just under one percent of the time to being used one percent of a percent of the time")

